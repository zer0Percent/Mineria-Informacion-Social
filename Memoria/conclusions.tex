\section{Conclusions}

% More information can be retrieved if it is considered the user information like the posts done by them or information related to the social network like followers, followings, etc.

The analysis at corpora level arouses that there exists a dominant natural language across all the datasets. The amount of retrieved data in English surpasses the amount for the remaining considered languages. This fact must be a trigger for developing multilingual tools for Natural Language downstream tasks like PoS tagging, tokenizers or stemmers but designed to cover the nuances of the social data. For the Twitter dataset and the keyword \textit{covid} there is a huge stream of tweets for any language considered regarding the Figure \ref{fig:twitter_postcounts_entity}. On the other hand, the small amount of hashtags per named entity could reflect that exploiting semantic information from this Twitter specific lingo would likely be tough. For the blog posts dataset derived from Twingly there exist more posts related to certain named entities as shown in the Figure \ref{fig:blogposts_postcount_lang_entity}. This is probably due to the geographic location where the real object represented by the named entity belongs to. This fact could affect to the popularity of a given named entity in a specific country. Lastly, the unbalanced nature of the Reddit dataset could be a good starting point to build a balanced dataset at the level of the target variable to be predicted.


\section{Further work}
Since the Twitter and blog posts dataset are not annotated, unsupervised approaches could be executed in order to detect events or discover topics. Clustering algorithms and generative models like Latent Dirichlet Allocation \citep{bleiLda} could be a relatively good starting point. However, to evaluate the quality of the clusters, intrinsic metrics must be considered since the dataset is unlabelled. Two metrics could be the average similarity within a cluster objects or the average similarity between the objects of one cluster with the objects of other clusters.


However, if the dataset were annotated, extrinsic metrics like F-value or Normalized Mutual Information (NMI) could be used to evaluate the clusters quality \citep{clusteringTopicModellingTwitterReddit}.
% The anotation suscites unsupervised or supervised apporaches to infer rules that allows to generalize the information. However, the unsupervised tasks becomes a challenge in the context of short texts, like tweets or SMS. Adatp the current nlp tools or add preprocessing steps to normalize the data or enrich it by using the metadata contained in the posts (links, hashtags...)