\section{Conclusions}

% More information can be retrieved if it is considered the user information like the posts done by them or information related to the social network like followers, followings, etc.

The analysis at corpora level arouses that there exists a dominant natural language across all the datasets. The amount of retrieved data in English surpasses the amount for the remaining considered languages. This fact must be a trigger for developing multilingual tools for Natural Language downstream tasks like PoS tagging, tokenizers or stemmers but designed to cover the nuances of the social data. For the Twitter dataset and the keyword \textit{covid} there is a huge stream of tweets for any language considered regarding the Figure \ref{fig:twitter_postcounts_entity}. On the other hand, the small amount of hashtags per named entity could reflect that exploiting semantic information from this Twitter specific lingo would likely be tough. For the blog posts dataset derived from Twingly there exist more posts related to certain named entities as shown in the Figure \ref{fig:blogposts_postcount_lang_entity}. This is probably due to the geographic location where the real object represented by the named entity belongs to. This fact could affect to the popularity of a given named entity in a specific country. Lastly, the unbalanced nature of the Reddit dataset could be a good starting point to build a balanced dataset at the level of the target variable to be predicted.


\section{Further work}
%TODO: deeper analysis at token level explain this!!!
Deeper analysis must be conducted in order to determine relative importances of the words for a given dataset and named entity in order to exploit them in downstream tasks like topic modelling and event detection.
\par Since the Twitter and blog posts dataset are not annotated, unsupervised approaches could be executed in order to detect events or discover topics. Clustering algorithms and generative models like Latent Dirichlet Allocation \citep{Blei2003} could be a relatively good starting point. However, to evaluate the quality of the clusters, intrinsic metrics must be considered since the dataset is unlabelled. Two metrics could be the average similarity within a cluster objects or the average similarity between the objects of one cluster with the objects of other clusters. However, if the dataset were annotated, extrinsic metrics like F-value or Normalized Mutual Information (NMI) could be used to evaluate the clusters quality \citep{clusteringTopicModellingTwitterReddit}.
